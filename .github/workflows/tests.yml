# GitHub Actions Workflow for Planet Wars

name: Tests

on:
  # Run on pull requests to any branch
  pull_request:
    branches: [ "**" ]
  
  # Run on pushes to main branch only
  # CRITICAL: This ensures coverage is uploaded for squash-merged commits
  # Without this, Codecov can't find base commit coverage for PR comparisons
  push:
    branches:
      - main
      - master
  
  # Allow manual trigger from GitHub Actions tab
  workflow_dispatch:

# Concurrency: Cancel outdated workflow runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
  # This cancels in-progress runs when a new commit is pushed to the same branch
  # group: Uniquely identifies this workflow run (workflow name + branch/PR ref)
  # cancel-in-progress: true means cancel old runs, false means queue them

# Jobs: The actual work to be done
jobs:
  # Job 1: Run all tests
  test:
    # Use Ubuntu (Linux) as the runner
    # GitHub provides: ubuntu-latest, windows-latest, macos-latest
    runs-on: ubuntu-latest
    
    # Strategy: Test on multiple Python versions (optional, currently just 3.11)
    strategy:
      matrix:
        python-version: ["3.11"]
    
    # Steps: Individual tasks that run sequentially
    steps:
      # Step 1: Check out the repository code
      - name: Checkout code
        uses: actions/checkout@v4
        # 'uses' means use a pre-built action from GitHub marketplace
        # checkout@v4 is the official action to clone your repo
      
      # Step 2: Set up Python environment
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
        # ${{ matrix.python-version }} is a variable from strategy.matrix
      
      # Step 3: Install system dependencies
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pygame ffmpeg libsdl2-mixer-2.0-0
        # 'run' executes shell commands
        # pygame needs SDL libraries, ffmpeg needed for audio processing
      
      # Step 4: Install pipenv
      - name: Install pipenv
        run: |
          python -m pip install --upgrade pip
          pip install pipenv
        # pipenv is not pre-installed, so we install it
      
      # Step 5: Install project dependencies
      - name: Install dependencies
        run: |
          pipenv install --dev
        # --dev installs both regular and development dependencies (pytest, etc.)
      
      # Step 6: Run unit tests with coverage
      - name: Run unit tests
        env:
          SDL_AUDIODRIVER: dummy
          SDL_VIDEODRIVER: dummy
        run: |
          pipenv run pytest tests/unit/ -v --tb=short --cov=game --cov-report=term
        # -v = verbose output
        # --tb=short = shorter traceback on failures
        # --cov=game measures code coverage while running tests (no re-run needed!)
        # --cov-report=term prints coverage summary to console
        # This step will FAIL the workflow if any test fails
        # SDL_AUDIODRIVER=dummy: Use fake audio device (no hardware needed)
        # SDL_VIDEODRIVER=dummy: Use fake display (no screen needed)
      
      # Step 7: Run integration tests (append to coverage)
      - name: Run integration tests
        env:
          SDL_AUDIODRIVER: dummy
          SDL_VIDEODRIVER: dummy
        run: |
          pipenv run pytest tests/integration/ -v --tb=short --cov=game --cov-append --cov-report=term --cov-report=xml
        # --cov-append adds to existing coverage data from unit tests
        # --cov-report=xml creates coverage.xml for upload
        # Separate step so you can see which test suite failed
        # SDL dummy drivers allow pygame to run without hardware
      
      # Step 8: Upload coverage to Codecov
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          fail_ci_if_error: false
          verbose: true
          flags: unittests
          name: codecov-umbrella
        # Uploads coverage report to codecov.io
        # token: GitHub secret containing Codecov upload token
        # Creates badge, PR comments, and detailed coverage reports
        # fail_ci_if_error: false means workflow won't fail if upload fails
        # verbose: true provides detailed logging for troubleshooting
        # flags: unittests helps organize coverage by test type
        # name: identifies this upload in Codecov UI
      
      # Step 9: Upload coverage artifact
      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: coverage.xml
        # Artifacts are files saved from the workflow
        # You can download them from GitHub Actions tab
        # if: always() means upload even if previous steps failed


